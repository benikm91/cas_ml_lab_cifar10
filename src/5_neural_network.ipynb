{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Feed-forward Neural Network\n",
    "\n",
    "In diesem Notebook schauen wir Neurale Netzwerke an.\n",
    "In der Praxis verwendet man für Bilderdaten üblicherweise Convolutional Neural Network (CNN), diese haben wir im Theorie Teil aber nicht im Detail angeschaut.\n",
    "Daher verwenden wir hier die Feed-forward Neural Networks mit einem Hidden Layer.\n",
    "\n",
    "Das Neural Network ist in `tensorflow` programmiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.plot(history.history['accuracy'], label='train_accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, activations, Sequential, losses\n",
    "from tensorflow.keras.regularizers import L2\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true: any, y_pred: any):\n",
    "    labels = np.unique(y_true)\n",
    "    fig = plt.figure(figsize=(len(labels), len(labels)))\n",
    "    ConfusionMatrixDisplay(\n",
    "      confusion_matrix=confusion_matrix(y_true=y_true, y_pred=y_pred, labels=labels, normalize='all'),\n",
    "      display_labels=labels\n",
    "    ).plot(ax=fig.gca(), cmap=\"BuPu\", xticks_rotation='vertical', include_values=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the data and split into features and labels\n",
    "with open('../data/train.pkl', 'rb') as f:\n",
    "    data_train = pickle.load(f)\n",
    "X_data = data_train[\"images\"]\n",
    "y_data = data_train[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing\n",
    "\n",
    "Für tensorflow müssen wir die Text-Labels (wie `frog`) in Zahlen verwandeln, dazu verwenden wir den `LabelEncoder`.\n",
    "\n",
    "Die Daten werden hier mittels `tf.image.per_image_standardization` standartisiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# tf.image.per_image_standardization ist ein übliches Preprocessing für Bilderdaten.\n",
    "X_train_std = tf.image.per_image_standardization(X_train).numpy()\n",
    "X_val_std = tf.image.per_image_standardization(X_val).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN (0 hidden layer -> Logistic Regression)\n",
    "\n",
    "Zuerst bauen wir die `Logistic Regression` als Neural Network nach.\n",
    "\n",
    "![Logistic Regression als Neural Network](./img/logistic_regression_as_nn.png)\n",
    "\n",
    "Die Performanz sollte ähnlich sein zu unserer `Logistic Regression` Baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lr = Sequential([\n",
    "    layers.InputLayer(input_shape=(32*32*3), name='input_layer'),\n",
    "    layers.Dense(10, activation=activations.linear, kernel_regularizer=L2(), name='output_layer'),\n",
    "])\n",
    "lr.compile(\n",
    "    optimizer='sgd',\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(lr.summary())\n",
    "\n",
    "history = lr.fit(X_train_std.reshape(-1, 32 * 32 * 3), y_train_enc, batch_size=128, epochs=40, validation_data=(X_val_std.reshape(-1, 32 * 32 * 3), y_val_enc))\n",
    "plot_history(history)\n",
    "\n",
    "y_val_hat_prob = lr.predict(X_val_std.reshape(-1, 32 * 32 * 3))\n",
    "y_val_hat = np.argmax(y_val_hat_prob, axis=1)\n",
    "\n",
    "print(accuracy_score(y_val_hat, y_val_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN (1 hidden layer) no Regularization\n",
    "\n",
    "Nun fügen wir einen `Hidden Layer` hinzu.\n",
    "\n",
    "![Neural Network mit einem Hidden Layer](./img/one_hidden_nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "nn = Sequential([\n",
    "    layers.InputLayer(input_shape=(32*32*3), name='input_layer'),\n",
    "    layers.Dense(1024, activation=activations.relu, name='hidden_layer'),\n",
    "    layers.Dense(10, activation=activations.linear, name='output_layer'),\n",
    "])\n",
    "nn.compile(\n",
    "    optimizer='sgd',\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(nn.summary())\n",
    "\n",
    "history = nn.fit(X_train_std.reshape(-1, 32 * 32 * 3), y_train_enc, batch_size=128, epochs=40, validation_data=(X_val_std.reshape(-1, 32 * 32 * 3), y_val_enc))\n",
    "plot_history(history)\n",
    "\n",
    "y_val_hat_prob = nn.predict(X_val_std.reshape(-1, 32 * 32 * 3))\n",
    "y_val_hat = np.argmax(y_val_hat_prob, axis=1)\n",
    "\n",
    "print(accuracy_score(y_val_hat, y_val_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NN (1 hidden layer) with L2 Regularization\n",
    "\n",
    "Nun fügen wir L2 Regularisierung hinzu, um gegen das Overfitting zu helfen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "nn_l2 = Sequential([\n",
    "    layers.InputLayer(input_shape=(32*32*3), name='input_layer'),\n",
    "    layers.Dense(1024, activation=activations.relu, kernel_regularizer=L2(0.01), name='hidden_layer'),\n",
    "    layers.Dense(10, activation=activations.linear, kernel_regularizer=L2(0.01), name='output_layer'),\n",
    "])\n",
    "nn_l2.compile(\n",
    "    optimizer='sgd',\n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(nn_l2.summary())\n",
    "\n",
    "history = nn_l2.fit(X_train_std.reshape(-1, 32 * 32 * 3), y_train_enc, batch_size=128, epochs=40, validation_data=(X_val_std.reshape(-1, 32 * 32 * 3), y_val_enc))\n",
    "plot_history(history)\n",
    "\n",
    "y_val_hat_prob = nn_l2.predict(X_val_std.reshape(-1, 32 * 32 * 3))\n",
    "y_val_hat = np.argmax(y_val_hat_prob, axis=1)\n",
    "\n",
    "print(accuracy_score(y_val_hat, y_val_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(\n",
    "    y_true=y_val,\n",
    "    y_pred=le.inverse_transform(y_val_hat)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict classes for test set\n",
    "\n",
    "If we are happy with the performance of our model on the validation set, we can apply it to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/test.pkl', 'rb') as f:\n",
    "    X_test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred_prob = nn_l2.predict(X_test.reshape(-1, 32 * 32 * 3))\n",
    "y_test_pred = np.argmax(y_test_pred_prob, axis=1)\n",
    "y_test_pred_enc = le.inverse_transform(y_test_pred)\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred_enc, columns=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit the predictions to Kaggle we write them into a .csv file, which you can manually submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_test_pred_df.to_csv('../out/neural_network.csv', header=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}